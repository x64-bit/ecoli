# -*- coding: utf-8 -*-
"""webscraper.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iYpAOR0M7vRD4TTiIeSHUkNDAAiAzRVm
"""

from tqdm import tqdm
from bs4 import BeautifulSoup
from time import sleep
import requests
import json
import pandas as pd
import time

def gen_year(year, table_name, region, col):
  """Generates Pandas DataFrame with a year's worth of data.
  
  Keyword args:
  year (str) - year of data to pull
  table_name (str) - name of table to pull
  region (str) - region to pull from table
  col (int) - column to pull from table
  """
  # Placeholder dataframe
  df = pd.DataFrame();
  
  for i in range(52):
    # Week num
    week = str(i+1)
    if (len(week) < 2):
      week = "0" + week
    
    # Placeholder
    url = (
        "https://wonder.cdc.gov/nndss/static/{0}/{1}/{2}-{3}-table{4}.html"
        .format(year, week, year, week, table_name))
    # Request url
    r = requests.get(url)
    # Load html content into BeautifulSoup for easy parsing
    soup = BeautifulSoup(r.content, 'html.parser')
    
    # Look for the table body (tbody), then extract all table rows (tr)
    rows = soup.select('table tr')
    for row in rows:
      # Extract header, convert to text, eliminate whitespace, use lowercase
      if (row.select_one('th').text.strip().lower() == region.lower()):
        print("Row found!")
        # Extract table values from row
        tds = row.select('td')
        # Find specified col
        cases = tds[col].text.strip()
        print("Cases: [" + cases + "]")
        # Check if col is empty (filled w/ dash mark), if not append to df
        if (cases != "-"):
          df = df.append([int(cases)], ignore_index=True)
        else:
          df = df.append([0], ignore_index=True)
        
    print("Finished week: " + week)
    print(df)
    time.sleep(12.5)
  
  return df

test = gen_year("2018", "2O", "Pacific", 5)
print(test)